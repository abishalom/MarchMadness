{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we clean up the data. We create 2 dataframes, one for winners and one for losers. Each has the same column names (team, score, fgm, fga, fgm3, fga3, ftm, fta, or, dr, ast, stl, blk, pf).\n",
    "<br> We will now use these dataframes to build our representative team vectors for the season, putting together the information from the winners and the losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = ['team', 'score', 'fgm', 'fga', 'fgm3', 'fga3', 'ftm', 'fta', 'or', 'dr', 'ast', 'stl', 'blk', 'pf']\n",
    "imp_attributes = ['team', 'score', 'fgm', 'fga', 'fgm3', 'fga3', 'ftm', 'fta', 'or', 'dr', 'ast', 'stl', 'blk']\n",
    "\n",
    "def load_team_data():\n",
    "    reg_season_data_filename = \"RegularSeasonDetailedResults.csv\"\n",
    "    #We load the data into a pandas dataframe.\n",
    "    reg_season_data = pd.read_csv(reg_season_data_filename)\n",
    "    # reg_season_data = reg_season_data.loc[lambda df: df.Season == 2003]\n",
    "    #Took out location and overtimes. Play around with what other stats we want to include. \n",
    "    \n",
    "    w = reg_season_data[['Season'] + ['W' + x for x in imp_attributes]]\n",
    "    win_remap = {'W'+x: x for x in imp_attributes}\n",
    "    winners = w.rename(index = str, columns = win_remap)\n",
    "    los_remap = {'L' + x:x for x in imp_attributes}\n",
    "    l = reg_season_data[['Season']+ ['L' + x for x in imp_attributes]]\n",
    "    losers = l.rename(index=str, columns = los_remap)\n",
    "    \n",
    "    #Know what seasons of data we are dealing with\n",
    "    reg_season_years = reg_season_data['Season'].unique()\n",
    "\n",
    "    #Here, we put all the data (from both winners and losers) into one dataframe. \n",
    "    team_data = pd.concat([winners, losers])\n",
    "\n",
    "    by_reg_season = {}\n",
    "    for year in reg_season_years:\n",
    "        s = team_data[team_data['Season']==year]\n",
    "    #     display(s)\n",
    "        s = s.drop(['Season'], axis = 1)\n",
    "        by_reg_season[year] = s\n",
    "    return by_reg_season, reg_season_years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by_reg_season, reg_season_years = load_team_data()\n",
    "# display(by_reg_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denominate the team vector to be represented as:\n",
    "\\[Score, FG Made, FG Attempted, 3 Pointers Made, 3 Pointers attempted, FT made, FT Attempted, Off Rebounds, Def Rebounds, Assists, Steals, Blocks\\]. (Later in the code we add the team's seed to their vectors)\n",
    "<br> <br>\n",
    "In this following cell we aggregate the data and calculate each team's average statistics for each year. To store this, we keep 1 dataframe (indexed by team) for each year of data. The pointers to these objects are stored in our dictionary, which serves as a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_vector_store(by_reg_season, reg_season_years):\n",
    "    # Create dictionary mapping year-> Dataframe of teams within that year.\n",
    "    team_vector_store = {}\n",
    "\n",
    "    for year in reg_season_years:\n",
    "        t = by_reg_season[year].groupby('team')[imp_attributes[1:]].mean()\n",
    "        team_vector_store[year] = t.apply(lambda x: x, axis = 0)\n",
    "    \n",
    "    return team_vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vector_store = get_team_vector_store(by_reg_season, reg_season_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to normalize the data. This could be used at whatever point we want. If we want a standardn normal distribution, set standard = True, otherwise we let standard=False for min/max normalization.\n",
    "\n",
    "We test using both methods of normalization to see which gave us better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(team_vector_store, standard = False):\n",
    "    \"\"\"\n",
    "    Function to normalize the data. \n",
    "    IMPORTANT: Modifies the argument passed in.\n",
    "    Set standard to True if normalizing to standard Gaussian,\n",
    "    False for min/max normalization. \n",
    "    \"\"\"\n",
    "    for y in reg_season_years:\n",
    "        if standard:\n",
    "            team_vector_store[y] = team_vector_store[y].apply(lambda x: (x - x.mean())/x.std(), axis = 0)\n",
    "        else:\n",
    "            team_vector_store[y] = team_vector_store[y].apply(lambda x: x/x.max(), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a matchup to be the difference between the vectors of team1 and team2. If team 1 wins, we classify the matchup as a 1, while we classify it as a 0 if team2 wins. Below is a quick example of how it could work. However, we must now add each team's seed to their representative vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2003\n",
    "m = team_vector_store[year]\n",
    "matchup_1 = (m.loc[1102] - m.loc[1103])\n",
    "matchup_1['class'] = 0\n",
    "# display(matchup_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we modify each season's team vector dataframe by adding each team's NCAA tournament seed. This will allow us to use this as a feature when outputting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seed_data(filename, standardize = False):\n",
    "    tourney_seeds_data = pd.read_csv(filename)\n",
    "    tourney_seeds_data = tourney_seeds_data.query('Season >= 2003')\n",
    "    tourney_seeds_data = tourney_seeds_data.reset_index(drop=True)\n",
    "    tourney_seeds_data.rename(str.lower, axis='columns', inplace = True)\n",
    "    tourney_seeds_data['seed'] = tourney_seeds_data['seed'].str.extract('(\\d+)', expand = False).astype(int)\n",
    "    if standardize:\n",
    "        tourney_seeds_data['seed'] = tourney_seeds_data['seed']/16\n",
    "    return tourney_seeds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_seeds_data = load_seed_data(\"TourneySeeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vector_store(team_vector_store, tourney_seeds_data):\n",
    "    #Joins the team vector store with the seed information.\n",
    "    #Allows us to consider seed as an attribute of the team.\n",
    "    #Eliminates the teams not in the tournament.\n",
    "    for s in reg_season_years:\n",
    "        relevant_data = tourney_seeds_data.query('season == {}'.format(s))\n",
    "        relevant_data = relevant_data.drop('season', axis = 1)\n",
    "        m = team_vector_store[s]\n",
    "        m = m.merge(relevant_data, how = 'outer', left_index = True, right_on = 'team')\n",
    "        m.set_index('team', inplace=True)\n",
    "        m = m[pd.notnull(m['seed'])]\n",
    "        team_vector_store[s] = m\n",
    "    return team_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vector_store = update_vector_store(team_vector_store, tourney_seeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_data(team_vector_store, standard = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must use our team vectors along with the matchups each season to build our feature vectors, which we will use for classification. A 1 will signify that the 1st team won, while a 0 means the 2nd team won.\n",
    "\n",
    "Our NCAA tournament data is in the same format as the regular season one. In order to have a combination of 1s and 0s, we will generate 2 different vectors for each matchup, where the first has team_1 = winning_team while the second has team_1 = losing_team. Because of the way our data is labeled, if we do not do this then all of our vectors will have classification 1 or 0, which won't allow our model to actually learn a decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(team_vector_store, classification = True):\n",
    "    \"\"\"\n",
    "    Function to generate the training/testing data.\n",
    "    Based on team_vector_store and the tourney detailed results.\n",
    "    If classification = True, generates for binary classification.\n",
    "    If classification = False, generates for regression.\n",
    "    \n",
    "    Returns training_data\n",
    "    \"\"\"\n",
    "    tourney_game_data = pd.read_csv(\"TourneyDetailedResults.csv\")\n",
    "    tourney_game_data = tourney_game_data[['Season', 'Wteam', 'Lteam', 'Wscore', 'Lscore']]\n",
    "\n",
    "\n",
    "    col_names = list(team_vector_store[2003]) + ['class']\n",
    "\n",
    "    train_matchup_data = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    for index, row in tourney_game_data.iterrows():\n",
    "        season, wteam, lteam, wscore, lscore = row\n",
    "        \n",
    "        #Winner is team 1, loser is team 2\n",
    "        game_vector_1 = team_vector_store[season].loc[wteam] - team_vector_store[season].loc[lteam]\n",
    "        if classification:\n",
    "            game_vector_1['class'] = 1\n",
    "        else:\n",
    "            game_vector_1['class'] = wscore - lscore\n",
    "        \n",
    "        #Loser is team 1, winner is team 2\n",
    "        game_vector_2 = team_vector_store[season].loc[lteam] - team_vector_store[season].loc[wteam]\n",
    "        if classification:\n",
    "            game_vector_2['class'] = 0\n",
    "        else:\n",
    "            game_vector_2['class'] = lscore - wscore\n",
    "        \n",
    "        train_matchup_data = train_matchup_data.append([game_vector_1, game_vector_2], ignore_index = True)\n",
    "        \n",
    "    return train_matchup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matchup_data_class = generate_training_data(team_vector_store, classification = True)\n",
    "train_matchup_data_reg = generate_training_data(team_vector_store, classification = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our training data built up. The X data will just be the rows except ('class'), while the Y data will simply be the column 'class'.\n",
    "\n",
    "Below, we define functions to build 2 different kinds of simple neural networks:\n",
    "1. A binary classification network: \n",
    "    - Takes matchup vectors (team_1 - team_2) as inputs, and outputs a binary digit prediction (1 if team_1 wins, 0 if team_2 wins).\n",
    "2. A regression network: \n",
    "    - Takes matchup vectors (team_1 - team_2) as inputs, and outputs a scalar prediction for the difference between scores (team_1_score - team_2_score).\n",
    "    - We then use these predicted scores to predict the matchup victor (1 if predicted score > 0, and 0 otherwise)\n",
    "    \n",
    "In order to evaluate the regression network's predictions, we define a prediction_percentage function which returns the percentage of games in which the victor is predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-655cc03774c2>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-655cc03774c2>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    kernel_regularizer = l1_l2(0, 0.001))\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def pred_percentage(y_true, y_pred):\n",
    "    y_true_sign = tf.sign(y_true)\n",
    "    y_pred_sign = tf.sign(y_pred)\n",
    "    mults = tf.multiply(y_true_sign, y_pred_sign)\n",
    "    return K.mean(mults+1)/2\n",
    "\n",
    "def build_keras_model(input_shape, num_units, num_layers, classification = True):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units = num_units, \n",
    "                    input_dim = input_shape[1], \n",
    "                    activation = 'relu')\n",
    "                    kernel_regularizer = l1_l2(0, 0.001))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dense(num_units, \n",
    "                        activation = 'relu'\n",
    "                        kernel_regularizer = l1_l2(0, 0.001)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "    if classification:\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = Adam(), metrics = ['accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss = 'mae', optimizer = Adam(), metrics = [pred_percentage])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, X_train, Y_train, X_test, Y_test, epochs):\n",
    "    model.fit(X_train, Y_train, epochs = epochs, batch_size = 1)\n",
    "    loss = model.evaluate(X_test, Y_test, batch_size = 1)\n",
    "    print(\"Loss was: {} and accuracy was: {}\".format(loss[0], loss[1]))\n",
    "    return loss[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use cross-validation (with 10 folds) to test the performance of our binary classification neural network. This process splits the data into 10 randomized chunks. Then, it uses $\\frac{9}{10}$ chunks to train the network, while using the final chunk to test the predictions. After this, the average accuracy is printed below, and serves as a proxy for the performance of this neural network on unknown data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold: 1\n",
      "Epoch 1/5\n",
      "1282/1282 [==============================] - 4s 3ms/step - loss: 0.7284 - acc: 0.5577\n",
      "Epoch 2/5\n",
      "1282/1282 [==============================] - 4s 3ms/step - loss: 0.6677 - acc: 0.5835\n",
      "Epoch 3/5\n",
      "1282/1282 [==============================] - 3s 3ms/step - loss: 0.6386 - acc: 0.6154\n",
      "Epoch 4/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6324 - acc: 0.6443\n",
      "Epoch 5/5\n",
      "1282/1282 [==============================] - 3s 3ms/step - loss: 0.6097 - acc: 0.6716\n",
      "144/144 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.5916101426507036 and accuracy was: 0.6944444444444444\n",
      "Running fold: 2\n",
      "Epoch 1/5\n",
      "1282/1282 [==============================] - 4s 3ms/step - loss: 0.7258 - acc: 0.5125\n",
      "Epoch 2/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6464 - acc: 0.6092\n",
      "Epoch 3/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6299 - acc: 0.6498A: 1s - \n",
      "Epoch 4/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6015 - acc: 0.6739\n",
      "Epoch 5/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6019 - acc: 0.6583\n",
      "144/144 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.5709913042891357 and accuracy was: 0.6875\n",
      "Running fold: 3\n",
      "Epoch 1/5\n",
      "1282/1282 [==============================] - 3s 3ms/step - loss: 0.7325 - acc: 0.5546\n",
      "Epoch 2/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6681 - acc: 0.6053\n",
      "Epoch 3/5\n",
      "1282/1282 [==============================] - 3s 3ms/step - loss: 0.6346 - acc: 0.6521\n",
      "Epoch 4/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6238 - acc: 0.6498\n",
      "Epoch 5/5\n",
      "1282/1282 [==============================] - 3s 2ms/step - loss: 0.6084 - acc: 0.6825\n",
      "144/144 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.554561141360965 and accuracy was: 0.7222222222222222\n",
      "Running fold: 4\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 0.6751 - acc: 0.5685\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6315 - acc: 0.6394\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6115 - acc: 0.6628\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6097 - acc: 0.6721\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6027 - acc: 0.6807\n",
      "142/142 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.578052643214313 and accuracy was: 0.7394366197183099\n",
      "Running fold: 5\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 0.7100 - acc: 0.5864\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6499 - acc: 0.6207\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6195 - acc: 0.6636\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.5924 - acc: 0.6931\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.5919 - acc: 0.6978\n",
      "142/142 [==============================] - 0s 3ms/step\n",
      "Loss was: 0.6005639878272171 and accuracy was: 0.6549295774647887\n",
      "Running fold: 6\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6919 - acc: 0.5724\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6320 - acc: 0.6371\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6171 - acc: 0.6682\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 0.6067 - acc: 0.6776\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 0.5969 - acc: 0.6776\n",
      "142/142 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.5394063033688237 and accuracy was: 0.7676056338028169\n",
      "Running fold: 7\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.7157 - acc: 0.5467\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 2s 2ms/step - loss: 0.6709 - acc: 0.5950\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 2s 2ms/step - loss: 0.6310 - acc: 0.6269\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6212 - acc: 0.6612\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6064 - acc: 0.6760A: 0s - loss: 0.6073 \n",
      "142/142 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.5663333618619912 and accuracy was: 0.7464788732394366\n",
      "Running fold: 8\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.7179 - acc: 0.5140\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 2s 2ms/step - loss: 0.6538 - acc: 0.6083\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 2s 2ms/step - loss: 0.6362 - acc: 0.6511\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 2s 2ms/step - loss: 0.6167 - acc: 0.6573\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.5940 - acc: 0.6830\n",
      "142/142 [==============================] - 0s 2ms/step\n",
      "Loss was: 0.5665890426493027 and accuracy was: 0.7323943661971831\n",
      "Running fold: 9\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.7026 - acc: 0.5530\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6500 - acc: 0.6129\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6089 - acc: 0.6706\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6175 - acc: 0.6713\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 0.6029 - acc: 0.6854\n",
      "142/142 [==============================] - 1s 4ms/step\n",
      "Loss was: 0.542754437485841 and accuracy was: 0.6690140845070423\n",
      "Running fold: 10\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.7082 - acc: 0.5600A: 3s - loss: 0.7686 - acc: 0. - ET\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6573 - acc: 0.6020\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6299 - acc: 0.6277\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 2ms/step - loss: 0.6219 - acc: 0.6698\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 0.6079 - acc: 0.6698\n",
      "142/142 [==============================] - 0s 3ms/step\n",
      "Loss was: 0.5974721278418118 and accuracy was: 0.6619718309859155\n",
      "The average accuracy of predictions was: 0.707599765258216\n"
     ]
    }
   ],
   "source": [
    "X_train_class = train_matchup_data_class.drop(['class'], axis = 1)\n",
    "input_shape = X_train_class.shape\n",
    "Y_train_class = train_matchup_data_class['class']\n",
    "\n",
    "num_units = 15\n",
    "num_layers = 3\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(Y_train_class, n_folds = n_folds, shuffle = True)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = build_keras_model(input_shape, num_units, num_layers, classification = True)\n",
    "    accuracy = train_and_evaluate(model, X_train_class.iloc[train], \n",
    "                       Y_train_class.iloc[train], \n",
    "                       X_train_class.iloc[test], \n",
    "                       Y_train_class.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"The average accuracy of predictions was: {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we test the performance of our regression neural network. As above, we use cross validation (with 10 folds) in order to test our network on our given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1262/1262 [==============================] - 4s 3ms/step - loss: 10.9941 - pred_percentage: 0.6101\n",
      "Epoch 2/5\n",
      "1262/1262 [==============================] - 3s 2ms/step - loss: 10.2886 - pred_percentage: 0.6767\n",
      "Epoch 3/5\n",
      "1262/1262 [==============================] - 3s 2ms/step - loss: 10.1585 - pred_percentage: 0.6878\n",
      "Epoch 4/5\n",
      "1262/1262 [==============================] - 3s 3ms/step - loss: 9.8238 - pred_percentage: 0.6957A: 0s - loss: 9.7443 - pr\n",
      "Epoch 5/5\n",
      "1262/1262 [==============================] - 3s 3ms/step - loss: 9.5860 - pred_percentage: 0.7021\n",
      "164/164 [==============================] - 1s 3ms/step\n",
      "Loss was: 9.383550516715864 and accuracy was: 0.6829268292682927\n",
      "Running fold: 2\n",
      "Epoch 1/5\n",
      "1265/1265 [==============================] - 4s 3ms/step - loss: 11.2359 - pred_percentage: 0.5462\n",
      "Epoch 2/5\n",
      "1265/1265 [==============================] - 3s 3ms/step - loss: 10.3326 - pred_percentage: 0.6553\n",
      "Epoch 3/5\n",
      "1265/1265 [==============================] - 3s 3ms/step - loss: 10.1564 - pred_percentage: 0.6632\n",
      "Epoch 4/5\n",
      "1265/1265 [==============================] - 3s 3ms/step - loss: 10.0413 - pred_percentage: 0.6798\n",
      "Epoch 5/5\n",
      "1265/1265 [==============================] - 3s 3ms/step - loss: 9.8054 - pred_percentage: 0.6830\n",
      "161/161 [==============================] - 1s 3ms/step\n",
      "Loss was: 10.298142087015306 and accuracy was: 0.7142857142857143\n",
      "Running fold: 3\n",
      "Epoch 1/5\n",
      "1272/1272 [==============================] - 4s 3ms/step - loss: 11.1824 - pred_percentage: 0.5369\n",
      "Epoch 2/5\n",
      "1272/1272 [==============================] - 3s 3ms/step - loss: 10.4024 - pred_percentage: 0.6682\n",
      "Epoch 3/5\n",
      "1272/1272 [==============================] - 3s 3ms/step - loss: 10.0004 - pred_percentage: 0.7013\n",
      "Epoch 4/5\n",
      "1272/1272 [==============================] - 3s 3ms/step - loss: 9.6488 - pred_percentage: 0.7091\n",
      "Epoch 5/5\n",
      "1272/1272 [==============================] - 3s 3ms/step - loss: 9.7818 - pred_percentage: 0.6871\n",
      "154/154 [==============================] - 1s 4ms/step\n",
      "Loss was: 9.924039685880983 and accuracy was: 0.6948051948051948\n",
      "Running fold: 4\n",
      "Epoch 1/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 11.0958 - pred_percentage: 0.5919\n",
      "Epoch 2/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 10.3305 - pred_percentage: 0.6674\n",
      "Epoch 3/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 10.0720 - pred_percentage: 0.6939\n",
      "Epoch 4/5\n",
      "1284/1284 [==============================] - 3s 3ms/step - loss: 9.9508 - pred_percentage: 0.6885\n",
      "Epoch 5/5\n",
      "1284/1284 [==============================] - 4s 3ms/step - loss: 9.9481 - pred_percentage: 0.6877\n",
      "142/142 [==============================] - 1s 4ms/step\n",
      "Loss was: 8.234766449726804 and accuracy was: 0.7605633802816901\n",
      "Running fold: 5\n",
      "Epoch 1/5\n",
      "1279/1279 [==============================] - 5s 4ms/step - loss: 10.9502 - pred_percentage: 0.5841\n",
      "Epoch 2/5\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 10.2959 - pred_percentage: 0.6630\n",
      "Epoch 3/5\n",
      "1279/1279 [==============================] - 4s 4ms/step - loss: 9.9075 - pred_percentage: 0.6927A: 2s - - ETA: 1s - l\n",
      "Epoch 4/5\n",
      "1279/1279 [==============================] - 5s 4ms/step - loss: 9.9172 - pred_percentage: 0.7013\n",
      "Epoch 5/5\n",
      "1279/1279 [==============================] - 4s 3ms/step - loss: 9.8369 - pred_percentage: 0.7060A: 2s - lo\n",
      "147/147 [==============================] - 1s 4ms/step\n",
      "Loss was: 9.229627866323302 and accuracy was: 0.6666666666666666\n",
      "Running fold: 6\n",
      "Epoch 1/5\n",
      "1289/1289 [==============================] - 6s 5ms/step - loss: 11.3948 - pred_percentage: 0.5539\n",
      "Epoch 2/5\n",
      "1289/1289 [==============================] - 5s 4ms/step - loss: 10.4564 - pred_percentage: 0.6439\n",
      "Epoch 3/5\n",
      "1289/1289 [==============================] - 5s 4ms/step - loss: 10.2639 - pred_percentage: 0.6788\n",
      "Epoch 4/5\n",
      "1289/1289 [==============================] - 4s 3ms/step - loss: 10.0665 - pred_percentage: 0.6928: 0s - loss: 10.0780 -\n",
      "Epoch 5/5\n",
      "1289/1289 [==============================] - 3s 2ms/step - loss: 9.9694 - pred_percentage: 0.6742\n",
      "137/137 [==============================] - 1s 5ms/step\n",
      "Loss was: 8.542408920552608 and accuracy was: 0.7226277372262774\n",
      "Running fold: 7\n",
      "Epoch 1/5\n",
      "1293/1293 [==============================] - 5s 4ms/step - loss: 11.1348 - pred_percentage: 0.5746\n",
      "Epoch 2/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 10.4488 - pred_percentage: 0.6690\n",
      "Epoch 3/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 10.1189 - pred_percentage: 0.6891\n",
      "Epoch 4/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.8523 - pred_percentage: 0.6906\n",
      "Epoch 5/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.8899 - pred_percentage: 0.6883\n",
      "133/133 [==============================] - 1s 5ms/step\n",
      "Loss was: 8.919827999028945 and accuracy was: 0.7218045112781954\n",
      "Running fold: 8\n",
      "Epoch 1/5\n",
      "1294/1294 [==============================] - 5s 4ms/step - loss: 10.9942 - pred_percentage: 0.5781\n",
      "Epoch 2/5\n",
      "1294/1294 [==============================] - 2s 2ms/step - loss: 10.2947 - pred_percentage: 0.6577\n",
      "Epoch 3/5\n",
      "1294/1294 [==============================] - 3s 2ms/step - loss: 9.9303 - pred_percentage: 0.6801\n",
      "Epoch 4/5\n",
      "1294/1294 [==============================] - 3s 2ms/step - loss: 9.7058 - pred_percentage: 0.6839\n",
      "Epoch 5/5\n",
      "1294/1294 [==============================] - 3s 2ms/step - loss: 9.6270 - pred_percentage: 0.7048\n",
      "132/132 [==============================] - 1s 4ms/step\n",
      "Loss was: 9.631114518100565 and accuracy was: 0.6590909090909091\n",
      "Running fold: 9\n",
      "Epoch 1/5\n",
      "1296/1296 [==============================] - 4s 3ms/step - loss: 11.3154 - pred_percentage: 0.5417\n",
      "Epoch 2/5\n",
      "1296/1296 [==============================] - 2s 2ms/step - loss: 10.5368 - pred_percentage: 0.6528\n",
      "Epoch 3/5\n",
      "1296/1296 [==============================] - 2s 2ms/step - loss: 9.9387 - pred_percentage: 0.6944\n",
      "Epoch 4/5\n",
      "1296/1296 [==============================] - 2s 2ms/step - loss: 9.8166 - pred_percentage: 0.6906\n",
      "Epoch 5/5\n",
      "1296/1296 [==============================] - 2s 2ms/step - loss: 9.6371 - pred_percentage: 0.7037\n",
      "130/130 [==============================] - 0s 4ms/step\n",
      "Loss was: 8.698153712199284 and accuracy was: 0.7384615384615385\n",
      "Running fold: 10\n",
      "Epoch 1/5\n",
      "1300/1300 [==============================] - 3s 3ms/step - loss: 11.1815 - pred_percentage: 0.5746\n",
      "Epoch 2/5\n",
      "1300/1300 [==============================] - 2s 2ms/step - loss: 10.2275 - pred_percentage: 0.6585\n",
      "Epoch 3/5\n",
      "1300/1300 [==============================] - 3s 2ms/step - loss: 10.2214 - pred_percentage: 0.6654\n",
      "Epoch 4/5\n",
      "1300/1300 [==============================] - 3s 2ms/step - loss: 9.9603 - pred_percentage: 0.6892\n",
      "Epoch 5/5\n",
      "1300/1300 [==============================] - 3s 3ms/step - loss: 9.7771 - pred_percentage: 0.7077\n",
      "126/126 [==============================] - 1s 7ms/step\n",
      "Loss was: 9.865797258558727 and accuracy was: 0.6746031746031746\n",
      "The average accuracy of predictions was: 0.7035835655967654\n"
     ]
    }
   ],
   "source": [
    "X_train_reg = train_matchup_data_reg.drop(['class'], axis = 1)\n",
    "input_shape = X_train_reg.shape\n",
    "Y_train_reg = train_matchup_data_reg['class']\n",
    "\n",
    "num_units = 15\n",
    "num_layers = 3\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(Y_train_reg, n_folds = n_folds, shuffle = True)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = build_keras_model(input_shape, num_units, num_layers, classification = False)\n",
    "    accuracy = train_and_evaluate(model, X_train_reg.iloc[train], \n",
    "                       Y_train_reg.iloc[train], \n",
    "                       X_train_reg.iloc[test], \n",
    "                       Y_train_reg.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"The average accuracy of predictions was: {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final neural network we will test is a bit more complex. Instead of taking a matchup vector as input, this neural network is simply provided the two team vectors. This allows the neural network to learn its own definition for a \"matchup\", instead of having to use ours. As with model #2, this is a regression network, which means its predictions represent the difference between the scores of the teams. \n",
    "\n",
    "In order to build this, we have to build our training set in a different way: building two different training sets in conjunction (one for team_1s and the other for team_2s), and then the labels in a third pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Generates data sets for inputs into the third neural network.\n",
    "    \"\"\"\n",
    "    tourney_game_data = pd.read_csv(\"TourneyDetailedResults.csv\")\n",
    "    tourney_game_data = tourney_game_data[['Season', 'Wteam', 'Lteam', 'Wscore', 'Lscore']]\n",
    "\n",
    "    # display(tourney_game_data)\n",
    "\n",
    "    col_names = list(team_vector_store[2003])\n",
    "    # print(list(col_names))\n",
    "\n",
    "    team_ones = pd.DataFrame(columns = col_names)\n",
    "    team_twos = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    one_minus_two = []\n",
    "    \n",
    "    for index, row in tourney_game_data.iterrows():\n",
    "        season, wteam, lteam, wscore, lscore = row\n",
    "        \n",
    "        win_vector = team_vector_store[season].loc[wteam]\n",
    "        lose_vector = team_vector_store[season].loc[lteam]\n",
    "        \n",
    "        #Win minus lose\n",
    "        team_ones = team_ones.append(win_vector)\n",
    "        team_twos = team_twos.append(lose_vector)\n",
    "        one_minus_two.append(wscore-lscore)\n",
    "    \n",
    "        #Lose minus win\n",
    "        team_ones = team_ones.append(lose_vector)\n",
    "        team_twos = team_twos.append(win_vector)\n",
    "        one_minus_two.append(lscore-wscore)\n",
    "    \n",
    "    one_minus_two = pd.Series(one_minus_two)\n",
    "    return team_ones, team_twos, one_minus_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team_ones, new_team_twos, one_minus_two = gen_new_data(team_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a function to create the third model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reg_model(team_feature_length):\n",
    "    \n",
    "    t1 = Input(shape = (team_feature_length, ))\n",
    "    t2 = Input(shape = (team_feature_length, ))\n",
    "    \n",
    "    team_transform = Dense(team_feature_length, \n",
    "                            activation = 'tanh', \n",
    "                            kernel_regularizer = l1_l2(0, 0.001)\n",
    "                          )\n",
    "    \n",
    "    team_1 = team_transform(t1)\n",
    "    team_2 = team_transform(t2)\n",
    "    \n",
    "    merge = Concatenate(axis=-1)([team_1, team_2])\n",
    "    \n",
    "    dropout = Dropout(0.2)(merge)\n",
    "    \n",
    "    x = Dense(team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(dropout)\n",
    "    \n",
    "    x = Dense(team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(x)\n",
    "    \n",
    "    x = Dense(team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(x)\n",
    "    \n",
    "    pred = Dense(1)(x) #linear activation for regression\n",
    "    model = Model(inputs = [t1, t2],\n",
    "                 outputs = pred)\n",
    "    model.compile(optimizer = 'Adam', loss = 'mae', metrics = [pred_percentage])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def new_train_and_evaluate(model, X_train, Y_train, X_test, Y_test, epochs):\n",
    "    model.fit(X_train, Y_train, epochs = epochs, batch_size = 1)\n",
    "    loss = model.evaluate(X_test, Y_test, batch_size = 1)\n",
    "    print(\"Loss was: {} and prediction percentage was: {}\".format(loss[0], loss[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we test this third neural network using the same process as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=10.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold: 1\n",
      "Epoch 1/5\n",
      "1270/1270 [==============================] - 4s 3ms/step - loss: 10.4591 - pred_percentage: 0.6843\n",
      "Epoch 2/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.7916 - pred_percentage: 0.7181\n",
      "Epoch 3/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.6639 - pred_percentage: 0.7087\n",
      "Epoch 4/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.4346 - pred_percentage: 0.7252\n",
      "Epoch 5/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.4127 - pred_percentage: 0.7228\n",
      "156/156 [==============================] - 1s 4ms/step\n",
      "Loss was: 8.734520721320923 and accuracy was: 0.7051282051282052\n",
      "Running fold: 2\n",
      "Epoch 1/5\n",
      "1266/1266 [==============================] - 5s 4ms/step - loss: 10.5428 - pred_percentage: 0.6596\n",
      "Epoch 2/5\n",
      "1266/1266 [==============================] - 4s 3ms/step - loss: 9.7503 - pred_percentage: 0.6998\n",
      "Epoch 3/5\n",
      "1266/1266 [==============================] - 3s 3ms/step - loss: 9.4108 - pred_percentage: 0.7180A: 0s - loss: 9.4242 - pred_percentag\n",
      "Epoch 4/5\n",
      "1266/1266 [==============================] - 3s 2ms/step - loss: 9.3150 - pred_percentage: 0.7220A: 0s - loss: 9.5348 - pr\n",
      "Epoch 5/5\n",
      "1266/1266 [==============================] - 3s 2ms/step - loss: 9.2334 - pred_percentage: 0.7070\n",
      "160/160 [==============================] - 1s 5ms/step\n",
      "Loss was: 9.84430358093232 and accuracy was: 0.71875\n",
      "Running fold: 3\n",
      "Epoch 1/5\n",
      "1272/1272 [==============================] - 4s 3ms/step - loss: 10.5497 - pred_percentage: 0.6769\n",
      "Epoch 2/5\n",
      "1272/1272 [==============================] - 3s 2ms/step - loss: 9.9043 - pred_percentage: 0.7013\n",
      "Epoch 3/5\n",
      "1272/1272 [==============================] - 3s 2ms/step - loss: 9.6825 - pred_percentage: 0.7083\n",
      "Epoch 4/5\n",
      "1272/1272 [==============================] - 3s 3ms/step - loss: 9.5420 - pred_percentage: 0.7186\n",
      "Epoch 5/5\n",
      "1272/1272 [==============================] - 2s 2ms/step - loss: 9.4672 - pred_percentage: 0.7178\n",
      "154/154 [==============================] - 1s 5ms/step\n",
      "Loss was: 9.465154426051425 and accuracy was: 0.6948051948051948\n",
      "Running fold: 4\n",
      "Epoch 1/5\n",
      "1270/1270 [==============================] - 5s 4ms/step - loss: 10.3034 - pred_percentage: 0.6661\n",
      "Epoch 2/5\n",
      "1270/1270 [==============================] - 4s 3ms/step - loss: 9.6892 - pred_percentage: 0.7024\n",
      "Epoch 3/5\n",
      "1270/1270 [==============================] - 3s 3ms/step - loss: 9.4609 - pred_percentage: 0.7071A: 0s - loss: 9.4965 - pred_percentage: \n",
      "Epoch 4/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.3536 - pred_percentage: 0.7087\n",
      "Epoch 5/5\n",
      "1270/1270 [==============================] - 3s 2ms/step - loss: 9.1975 - pred_percentage: 0.7252\n",
      "156/156 [==============================] - 1s 5ms/step\n",
      "Loss was: 10.785579113528515 and accuracy was: 0.6987179487179487\n",
      "Running fold: 5\n",
      "Epoch 1/5\n",
      "1277/1277 [==============================] - 5s 4ms/step - loss: 10.4522 - pred_percentage: 0.6547\n",
      "Epoch 2/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 9.6683 - pred_percentage: 0.7063\n",
      "Epoch 3/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 9.4674 - pred_percentage: 0.6993\n",
      "Epoch 4/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 9.3585 - pred_percentage: 0.7040\n",
      "Epoch 5/5\n",
      "1277/1277 [==============================] - 3s 2ms/step - loss: 9.1998 - pred_percentage: 0.7212\n",
      "149/149 [==============================] - 1s 6ms/step\n",
      "Loss was: 9.785320113769314 and accuracy was: 0.6778523489932886\n",
      "Running fold: 6\n",
      "Epoch 1/5\n",
      "1291/1291 [==============================] - 5s 4ms/step - loss: 10.6616 - pred_percentage: 0.6522\n",
      "Epoch 2/5\n",
      "1291/1291 [==============================] - 3s 2ms/step - loss: 9.7859 - pred_percentage: 0.7002\n",
      "Epoch 3/5\n",
      "1291/1291 [==============================] - 3s 2ms/step - loss: 9.5693 - pred_percentage: 0.7088A: 1s - loss: 9.1\n",
      "Epoch 4/5\n",
      "1291/1291 [==============================] - 3s 3ms/step - loss: 9.4417 - pred_percentage: 0.7072A: 0s - loss: 9.4586 - pred_percenta\n",
      "Epoch 5/5\n",
      "1291/1291 [==============================] - 3s 2ms/step - loss: 9.3483 - pred_percentage: 0.7173\n",
      "135/135 [==============================] - 1s 8ms/step\n",
      "Loss was: 9.599919786497399 and accuracy was: 0.6592592592592592\n",
      "Running fold: 7\n",
      "Epoch 1/5\n",
      "1293/1293 [==============================] - 4s 3ms/step - loss: 10.6426 - pred_percentage: 0.6458\n",
      "Epoch 2/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.8010 - pred_percentage: 0.6984\n",
      "Epoch 3/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.6112 - pred_percentage: 0.7022\n",
      "Epoch 4/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.4382 - pred_percentage: 0.7022\n",
      "Epoch 5/5\n",
      "1293/1293 [==============================] - 3s 2ms/step - loss: 9.2932 - pred_percentage: 0.7208\n",
      "133/133 [==============================] - 1s 6ms/step\n",
      "Loss was: 8.948754704312273 and accuracy was: 0.7518796992481203\n",
      "Running fold: 8\n",
      "Epoch 1/5\n",
      "1299/1299 [==============================] - 5s 3ms/step - loss: 10.6138 - pred_percentage: 0.6674\n",
      "Epoch 2/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.8578 - pred_percentage: 0.6952\n",
      "Epoch 3/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.6988 - pred_percentage: 0.7021A: 1s - loss: 9.9103\n",
      "Epoch 4/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.4927 - pred_percentage: 0.6990\n",
      "Epoch 5/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.4335 - pred_percentage: 0.7144\n",
      "127/127 [==============================] - 1s 8ms/step\n",
      "Loss was: 8.233466921300868 and accuracy was: 0.7480314960629921\n",
      "Running fold: 9\n",
      "Epoch 1/5\n",
      "1297/1297 [==============================] - 5s 4ms/step - loss: 10.4211 - pred_percentage: 0.6654\n",
      "Epoch 2/5\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 9.7333 - pred_percentage: 0.6970\n",
      "Epoch 3/5\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 9.5093 - pred_percentage: 0.7140A: 0s - loss: 9.6459 - pred_perc\n",
      "Epoch 4/5\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 9.4185 - pred_percentage: 0.7155\n",
      "Epoch 5/5\n",
      "1297/1297 [==============================] - 4s 3ms/step - loss: 9.3834 - pred_percentage: 0.7124\n",
      "129/129 [==============================] - 1s 8ms/step\n",
      "Loss was: 8.79556186667593 and accuracy was: 0.7441860465116279\n",
      "Running fold: 10\n",
      "Epoch 1/5\n",
      "1299/1299 [==============================] - 6s 4ms/step - loss: 10.5819 - pred_percentage: 0.6490\n",
      "Epoch 2/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.8613 - pred_percentage: 0.6882\n",
      "Epoch 3/5\n",
      "1299/1299 [==============================] - 5s 4ms/step - loss: 9.6418 - pred_percentage: 0.7075\n",
      "Epoch 4/5\n",
      "1299/1299 [==============================] - 3s 3ms/step - loss: 9.4833 - pred_percentage: 0.7059\n",
      "Epoch 5/5\n",
      "1299/1299 [==============================] - 3s 2ms/step - loss: 9.4498 - pred_percentage: 0.6990\n",
      "127/127 [==============================] - 1s 9ms/step\n",
      "Loss was: 9.489417531828241 and accuracy was: 0.7322834645669292\n",
      "Average prediction accuracy: 0.7130893663293566\n"
     ]
    }
   ],
   "source": [
    "# display(one_minus_two)\n",
    "team_feature_length = len(imp_attributes)\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(one_minus_two, n_folds = n_folds, shuffle = True)\n",
    "# folds = StratifiedKFold(n_folds = n_folds, shuffle=True)\n",
    "\n",
    "percentages = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = make_reg_model(team_feature_length)\n",
    "    percentage =train_and_evaluate(model,\n",
    "                       [new_team_ones.iloc[train], new_team_twos.iloc[train]],\n",
    "                       one_minus_two.iloc[train], \n",
    "                       [new_team_ones.iloc[test], new_team_twos.iloc[test]],\n",
    "                       one_minus_two.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    percentages.append(percentage)\n",
    "\n",
    "print(\"Average prediction accuracy: {}\".format(np.mean(percentages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created and tested 3 different models:\n",
    "1. Simple binary classifier. \n",
    "    - Uses our definition of matchups (team_1 - team_2), and outputs 1 if team_1 wins, 0 if team_2 wins.\n",
    "\n",
    "2. Simple Regression.\n",
    "    - Uses our definition of matchups, and tries to predict the difference between points of team_1 and team_2.\n",
    "    - We then use a scoring function (return 1 if score_diff > 0, and 0 otherwise) in order to generate predictions.\n",
    "\n",
    "3. More Complex Regression.\n",
    "    - We feed just the team vectors into the model, and let the model learn an effective definition for what a matchup is.\n",
    "    - The model then outputs a prediction of the score differential (team_1_score - team_2_score).\n",
    "    - We then use the scoring function defined above to generate predictions.\n",
    "    \n",
    "    \n",
    "\n",
    "Now we will use these models (and the training data) in order to generate predictions for the matchups between 2011-2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matchup_testing_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Function to generate the training/testing data.\n",
    "    Based on team_vector_store and the tourney detailed results.\n",
    "    If classification = True, generates for binary classification.\n",
    "    If classification = False, generates for regression.\n",
    "    \n",
    "    Returns training_data\n",
    "    \"\"\"\n",
    "    col_names = list(team_vector_store[2003])\n",
    "\n",
    "    testing_matchup_data = pd.DataFrame(columns = col_names)\n",
    "    matchups = []\n",
    "    \n",
    "    for year in [2011, 2012, 2013]:\n",
    "        season_data = team_vector_store[year].sort_index()\n",
    "        for i1, row1 in season_data.iterrows():\n",
    "            for i2, row2 in season_data.iterrows():\n",
    "#                 print(row2)\n",
    "                if i2 > i1:\n",
    "                    matchups.append([year, i1, i2])\n",
    "                    matchup = row1 - row2\n",
    "                    testing_matchup_data = testing_matchup_data.append([matchup], ignore_index = True)\n",
    "\n",
    "    return testing_matchup_data, matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_data, matchups = generate_matchup_testing_data(team_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_to_csv(model, X_train, Y_train, outfile, testing_data, matchups, classification = True):\n",
    "    model.fit(X_train, Y_train, epochs = 5, batch_size = 1)\n",
    "    if classification:\n",
    "        predictions = model.predict_classes(testing_data)\n",
    "    else:\n",
    "        predictions = model.predict(testing_data)\n",
    "        \n",
    "    result = []\n",
    "    for i in range(len(matchups)):\n",
    "        representation = '_'.join([str(matchups[i][0]), str(matchups[i][1]), str(matchups[i][2])])\n",
    "        if classification:\n",
    "            representation = [representation] + [str(predictions[i][0])]\n",
    "        else:\n",
    "            pred = 1 if predictions[i][0] > 0 else 0\n",
    "            representation = [representation] + [str(pred)]\n",
    "        result.append(representation)\n",
    "\n",
    "    # print(result)\n",
    "    result = pd.DataFrame(data = result, columns = ['game_ID', 'Prediction'])\n",
    "    result.to_csv(outfile, index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1426/1426 [==============================] - 5s 4ms/step - loss: 0.7464 - acc: 0.5554\n",
      "Epoch 2/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.6533 - acc: 0.6094\n",
      "Epoch 3/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.6179 - acc: 0.6711\n",
      "Epoch 4/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.6074 - acc: 0.6795\n",
      "Epoch 5/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 0.5976 - acc: 0.6935A: 0s - loss: 0.\n"
     ]
    }
   ],
   "source": [
    "X_train_class = train_matchup_data_class.drop(['class'], axis = 1)\n",
    "input_shape = X_train_class.shape\n",
    "Y_train_class = train_matchup_data_class['class']\n",
    "binary_class_model = build_keras_model(input_shape, \n",
    "                                       num_units = 15, \n",
    "                                       num_layers = 3, \n",
    "                                       classification = True)\n",
    "\n",
    "generate_predictions_to_csv(binary_class_model, \n",
    "                            X_train_class, \n",
    "                            Y_train_class, \n",
    "                            \"bin_predictions.csv\",\n",
    "                            matchup_data,\n",
    "                            matchups,\n",
    "                            classification = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1426/1426 [==============================] - 5s 3ms/step - loss: 11.2351 - pred_percentage: 0.5631\n",
      "Epoch 2/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 10.1438 - pred_percentage: 0.6648\n",
      "Epoch 3/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 10.0996 - pred_percentage: 0.6732\n",
      "Epoch 4/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.9595 - pred_percentage: 0.6985\n",
      "Epoch 5/5\n",
      "1426/1426 [==============================] - 3s 2ms/step - loss: 9.6019 - pred_percentage: 0.7069\n"
     ]
    }
   ],
   "source": [
    "X_train_reg = train_matchup_data_reg.drop(['class'], axis = 1)\n",
    "input_shape = X_train_reg.shape\n",
    "Y_train_reg = train_matchup_data_reg['class']\n",
    "\n",
    "simple_regression_model = build_keras_model(input_shape, \n",
    "                                            num_units = 15, \n",
    "                                            num_layers = 3, \n",
    "                                            classification = False)\n",
    "\n",
    "generate_predictions_to_csv(simple_regression_model, \n",
    "                            X_train_reg, \n",
    "                            Y_train_reg, \n",
    "                            \"simple_reg_predictions.csv\",\n",
    "                            matchup_data,\n",
    "                            matchups,\n",
    "                            classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indiv_testing_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Function to generate the testing data.\n",
    "    \"\"\"\n",
    "    col_names = list(team_vector_store[2003])\n",
    "\n",
    "    team_ones = pd.DataFrame(columns = col_names)\n",
    "    team_twos = pd.DataFrame(columns = col_names)\n",
    "    matchups = []\n",
    "    \n",
    "    for year in [2011, 2012, 2013]:\n",
    "        season_data = team_vector_store[year].sort_index()\n",
    "        for i1, row1 in season_data.iterrows():\n",
    "            for i2, row2 in season_data.iterrows():\n",
    "#                 print(row2)\n",
    "                if i2 > i1:\n",
    "                    team_ones = team_ones.append(row1, ignore_index = True)\n",
    "                    team_twos = team_twos.append(row2, ignore_index = True)\n",
    "                    matchups.append([year, i1, i2])\n",
    "                    \n",
    "    return [team_ones, team_twos], matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1426/1426 [==============================] - 6s 4ms/step - loss: 10.4085 - pred_percentage: 0.6732\n",
      "Epoch 2/5\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.6723 - pred_percentage: 0.7062\n",
      "Epoch 3/5\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.4016 - pred_percentage: 0.7160\n",
      "Epoch 4/5\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.3995 - pred_percentage: 0.7153\n",
      "Epoch 5/5\n",
      "1426/1426 [==============================] - 4s 3ms/step - loss: 9.2462 - pred_percentage: 0.7090\n"
     ]
    }
   ],
   "source": [
    "X_train = [new_team_ones, new_team_twos]\n",
    "team_dim = len(imp_attributes)\n",
    "Y_train = one_minus_two\n",
    "\n",
    "complex_regression_model = make_reg_model(team_dim)\n",
    "indiv_testing_data, matchups = generate_indiv_testing_data(team_vector_store)\n",
    "\n",
    "generate_predictions_to_csv(complex_regression_model,\n",
    "                           X_train,\n",
    "                           Y_train,\n",
    "                           \"complex_reg_predictions.csv\",\n",
    "                           indiv_testing_data,\n",
    "                           matchups,\n",
    "                           classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
