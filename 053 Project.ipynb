{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Input, Concatenate\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import csv\n",
    "import pydot\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we clean up the data. We create 2 dataframes, one for winners and one for losers. Each has the same column names (team, score, fgm, fga, fgm3, fga3, ftm, fta, or, dr, ast, stl, blk, pf).\n",
    "<br> We will now use these dataframes to build our representative team vectors for the season, putting together the information from the winners and the losers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = ['team', 'score', 'fgm', 'fga', 'fgm3', 'fga3', 'ftm', 'fta', 'or', 'dr', 'ast', 'stl', 'blk', 'pf']\n",
    "imp_attributes = ['team', 'score', 'fgm', 'fga', 'fgm3', 'fga3', 'ftm', 'fta', 'or', 'dr', 'ast', 'stl', 'blk']\n",
    "\n",
    "def load_team_data():\n",
    "    reg_season_data_filename = \"RegularSeasonDetailedResults.csv\"\n",
    "    #We load the data into a pandas dataframe.\n",
    "    reg_season_data = pd.read_csv(reg_season_data_filename)\n",
    "    # reg_season_data = reg_season_data.loc[lambda df: df.Season == 2003]\n",
    "    #Took out location and overtimes. Play around with what other stats we want to include. \n",
    "    \n",
    "    w = reg_season_data[['Season'] + ['W' + x for x in imp_attributes]]\n",
    "    win_remap = {'W'+x: x for x in imp_attributes}\n",
    "    winners = w.rename(index = str, columns = win_remap)\n",
    "    los_remap = {'L' + x:x for x in imp_attributes}\n",
    "    l = reg_season_data[['Season']+ ['L' + x for x in imp_attributes]]\n",
    "    losers = l.rename(index=str, columns = los_remap)\n",
    "    \n",
    "    #Know what seasons of data we are dealing with\n",
    "    reg_season_years = reg_season_data['Season'].unique()\n",
    "\n",
    "    #Here, we put all the data (from both winners and losers) into one dataframe. \n",
    "    team_data = pd.concat([winners, losers])\n",
    "\n",
    "    by_reg_season = {}\n",
    "    for year in reg_season_years:\n",
    "        s = team_data[team_data['Season']==year]\n",
    "    #     display(s)\n",
    "        s = s.drop(['Season'], axis = 1)\n",
    "        by_reg_season[year] = s\n",
    "    return by_reg_season, reg_season_years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "by_reg_season, reg_season_years = load_team_data()\n",
    "# display(by_reg_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denominate the team vector to be represented as:\n",
    "\\[Score, FG Made, FG Attempted, 3 Pointers Made, 3 Pointers attempted, FT made, FT Attempted, Off Rebounds, Def Rebounds, Assists, Steals, Blocks\\]. (Later in the code we add the team's seed to their vectors)\n",
    "<br> <br>\n",
    "In this following cell we aggregate the data and calculate each team's average statistics for each year. To store this, we keep 1 dataframe (indexed by team) for each year of data. The pointers to these objects are stored in our dictionary, which serves as a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_vector_store(by_reg_season, reg_season_years):\n",
    "    # Create dictionary mapping year-> Dataframe of teams within that year.\n",
    "    team_vector_store = {}\n",
    "\n",
    "    for year in reg_season_years:\n",
    "        t = by_reg_season[year].groupby('team')[imp_attributes[1:]].mean()\n",
    "        team_vector_store[year] = t.apply(lambda x: x, axis = 0)\n",
    "    \n",
    "    return team_vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vector_store = get_team_vector_store(by_reg_season, reg_season_years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to normalize the data. This could be used at whatever point we want. If we want a standardn normal distribution, set standard = True, otherwise we let standard=False for min/max normalization.\n",
    "\n",
    "We test using both methods of normalization to see which gave us better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(team_vector_store, standard = False):\n",
    "    \"\"\"\n",
    "    Function to normalize the data. \n",
    "    IMPORTANT: Modifies the argument passed in.\n",
    "    Set standard to True if normalizing to standard Gaussian,\n",
    "    False for min/max normalization. \n",
    "    \"\"\"\n",
    "    for y in reg_season_years:\n",
    "        if standard:\n",
    "            team_vector_store[y] = team_vector_store[y].apply(lambda x: (x - x.mean())/x.std(), axis = 0)\n",
    "        else:\n",
    "            team_vector_store[y] = team_vector_store[y].apply(lambda x: x/x.max(), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a matchup to be the difference between the vectors of team1 and team2. If team 1 wins, we classify the matchup as a 1, while we classify it as a 0 if team2 wins. Below is a quick example of how it could work. However, we must now add each team's seed to their representative vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2017\n",
    "m = team_vector_store[year]\n",
    "matchup_1 = (m.loc[1274] - m.loc[1199])\n",
    "matchup_1['class'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we modify each season's team vector dataframe by adding each team's NCAA tournament seed. This will allow us to use this as a feature when outputting predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_seed_data(filename):\n",
    "    tourney_seeds_data = pd.read_csv(filename)\n",
    "    tourney_seeds_data = tourney_seeds_data.query('Season >= 2003')\n",
    "    tourney_seeds_data = tourney_seeds_data.reset_index(drop=True)\n",
    "    tourney_seeds_data.rename(str.lower, axis='columns', inplace = True)\n",
    "    tourney_seeds_data['seed'] = tourney_seeds_data['seed'].str.extract('(\\d+)', expand = False).astype(int)\n",
    "    return tourney_seeds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_seeds_data = load_seed_data(\"TourneySeeds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vector_store(team_vector_store, tourney_seeds_data):\n",
    "    #Joins the team vector store with the seed information.\n",
    "    #Allows us to consider seed as an attribute of the team.\n",
    "    #Eliminates the teams not in the tournament.\n",
    "    for s in reg_season_years:\n",
    "        relevant_data = tourney_seeds_data.query('season == {}'.format(s))\n",
    "        relevant_data = relevant_data.drop('season', axis = 1)\n",
    "        m = team_vector_store[s]\n",
    "        m = m.merge(relevant_data, how = 'outer', left_index = True, right_on = 'team')\n",
    "        m.set_index('team', inplace=True)\n",
    "        m = m[pd.notnull(m['seed'])]\n",
    "        team_vector_store[s] = m\n",
    "    return team_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_vector_store = update_vector_store(team_vector_store, tourney_seeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_data(team_vector_store, standard = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we must use our team vectors along with the matchups each season to build our feature vectors, which we will use for classification. A 1 will signify that the 1st team won, while a 0 means the 2nd team won.\n",
    "\n",
    "Our NCAA tournament data is in the same format as the regular season one. In order to have a combination of 1s and 0s, we will generate 2 different vectors for each matchup, where the first has team_1 = winning_team while the second has team_1 = losing_team. Because of the way our data is labeled, if we do not do this then all of our vectors will have classification 1 or 0, which won't allow our model to actually learn a decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(team_vector_store, classification = True):\n",
    "    \"\"\"\n",
    "    Function to generate the training/testing data.\n",
    "    Based on team_vector_store and the tourney detailed results.\n",
    "    If classification = True, generates for binary classification.\n",
    "    If classification = False, generates for regression.\n",
    "    \n",
    "    Returns training_data\n",
    "    \"\"\"\n",
    "    tourney_game_data = pd.read_csv(\"TourneyDetailedResults.csv\")\n",
    "    tourney_game_data = tourney_game_data[['Season', 'Wteam', 'Lteam', 'Wscore', 'Lscore']]\n",
    "\n",
    "\n",
    "    col_names = list(team_vector_store[2003]) + ['class']\n",
    "\n",
    "    train_matchup_data = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    for index, row in tourney_game_data.iterrows():\n",
    "        season, wteam, lteam, wscore, lscore = row\n",
    "        \n",
    "        #Winner is team 1, loser is team 2\n",
    "        game_vector_1 = team_vector_store[season].loc[wteam] - team_vector_store[season].loc[lteam]\n",
    "        if classification:\n",
    "            game_vector_1['class'] = 1\n",
    "        else:\n",
    "            game_vector_1['class'] = wscore - lscore\n",
    "        \n",
    "        #Loser is team 1, winner is team 2\n",
    "        game_vector_2 = team_vector_store[season].loc[lteam] - team_vector_store[season].loc[wteam]\n",
    "        if classification:\n",
    "            game_vector_2['class'] = 0\n",
    "        else:\n",
    "            game_vector_2['class'] = lscore - wscore\n",
    "        \n",
    "        train_matchup_data = train_matchup_data.append([game_vector_1, game_vector_2], ignore_index = True)\n",
    "        \n",
    "    return train_matchup_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matchup_data_class = generate_training_data(team_vector_store, classification = True)\n",
    "train_matchup_data_reg = generate_training_data(team_vector_store, classification = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our training data built up. The X data will just be the rows except ('class'), while the Y data will simply be the column 'class'.\n",
    "\n",
    "Below, we define functions to build 2 different kinds of simple neural networks:\n",
    "1. A binary classification network: \n",
    "    - Takes matchup vectors (team_1 - team_2) as inputs, and outputs a binary digit prediction (1 if team_1 wins, 0 if team_2 wins).\n",
    "2. A regression network: \n",
    "    - Takes matchup vectors (team_1 - team_2) as inputs, and outputs a scalar prediction for the difference between scores (team_1_score - team_2_score).\n",
    "    - We then use these predicted scores to predict the matchup victor (1 if predicted score > 0, and 0 otherwise)\n",
    "    \n",
    "In order to evaluate the regression network's predictions, we define a prediction_percentage function which returns the percentage of games in which the victor is predicted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_percentage(y_true, y_pred):\n",
    "    y_true_sign = tf.sign(y_true)\n",
    "    y_pred_sign = tf.sign(y_pred)\n",
    "    mults = tf.multiply(y_true_sign, y_pred_sign)\n",
    "    return K.mean(mults+1)/2\n",
    "\n",
    "def build_keras_model(input_shape, num_units, num_layers, classification = True):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(units = num_units, \n",
    "                    input_dim = input_shape[1], \n",
    "                    activation = 'relu',\n",
    "                    kernel_regularizer = l1_l2(0, 0.001)))\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dense(num_units, \n",
    "                        activation = 'relu',\n",
    "                        kernel_regularizer = l1_l2(0, 0.001)))\n",
    "#         model.add(Dropout(0.25))\n",
    "    \n",
    "    if classification:\n",
    "        model.add(Dense(1, activation = 'sigmoid'))\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = Adam(), metrics = ['accuracy'])\n",
    "    else:\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss = 'mae', optimizer = Adam(), metrics = [pred_percentage])\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate(model, X_train, Y_train, X_test, Y_test, epochs):\n",
    "    model.fit(X_train, Y_train, epochs = epochs, batch_size = 1)\n",
    "    loss = model.evaluate(X_test, Y_test, batch_size = 1)\n",
    "    print(\"Loss was: {} and accuracy was: {}\".format(loss[0], loss[1]))\n",
    "    return loss[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use cross-validation (with 10 folds) to test the performance of our binary classification neural network. This process splits the data into 10 randomized chunks. Then, it uses $\\frac{9}{10}$ chunks to train the network, while using the final chunk to test the predictions. After this, the average accuracy is printed below, and serves as a proxy for the performance of this neural network on unknown data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class = train_matchup_data_class.drop(['class'], axis = 1)\n",
    "input_shape = X_train_class.shape\n",
    "Y_train_class = train_matchup_data_class['class']\n",
    "\n",
    "num_units = 2*len(imp_attributes)\n",
    "num_layers = 3\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(Y_train_class, n_folds = n_folds, shuffle = True)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = build_keras_model(input_shape, num_units, num_layers, classification = True)\n",
    "    accuracy = train_and_evaluate(model, X_train_class.iloc[train], \n",
    "                       Y_train_class.iloc[train], \n",
    "                       X_train_class.iloc[test], \n",
    "                       Y_train_class.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"The average accuracy of predictions was: {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we test the performance of our regression neural network. As above, we use cross validation (with 10 folds) in order to test our network on our given dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = train_matchup_data_reg.drop(['class'], axis = 1)\n",
    "input_shape = X_train_reg.shape\n",
    "Y_train_reg = train_matchup_data_reg['class']\n",
    "\n",
    "num_units = 2*len(imp_attributes)\n",
    "num_layers = 3\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(Y_train_reg, n_folds = n_folds, shuffle = True)\n",
    "\n",
    "\n",
    "accuracies = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = build_keras_model(input_shape, num_units, num_layers, classification = False)\n",
    "    accuracy = train_and_evaluate(model, X_train_reg.iloc[train], \n",
    "                       Y_train_reg.iloc[train], \n",
    "                       X_train_reg.iloc[test], \n",
    "                       Y_train_reg.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"The average accuracy of predictions was: {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final neural network we will test is a bit more complex. Instead of taking a matchup vector as input, this neural network is simply provided the two team vectors. This allows the neural network to learn its own definition for a \"matchup\", instead of having to use ours. As with model #2, this is a regression network, which means its predictions represent the difference between the scores of the teams. \n",
    "\n",
    "In order to build this, we have to build our training set in a different way: building two different training sets in conjunction (one for team_1s and the other for team_2s), and then the labels in a third pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_new_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Generates data sets for inputs into the third neural network.\n",
    "    \"\"\"\n",
    "    tourney_game_data = pd.read_csv(\"TourneyDetailedResults.csv\")\n",
    "    tourney_game_data = tourney_game_data[['Season', 'Wteam', 'Lteam', 'Wscore', 'Lscore']]\n",
    "\n",
    "    # display(tourney_game_data)\n",
    "\n",
    "    col_names = list(team_vector_store[2003])\n",
    "    # print(list(col_names))\n",
    "\n",
    "    team_ones = pd.DataFrame(columns = col_names)\n",
    "    team_twos = pd.DataFrame(columns = col_names)\n",
    "\n",
    "    one_minus_two = []\n",
    "    \n",
    "    for index, row in tourney_game_data.iterrows():\n",
    "        season, wteam, lteam, wscore, lscore = row\n",
    "        \n",
    "        win_vector = team_vector_store[season].loc[wteam]\n",
    "        lose_vector = team_vector_store[season].loc[lteam]\n",
    "        \n",
    "        #Win minus lose\n",
    "        team_ones = team_ones.append(win_vector)\n",
    "        team_twos = team_twos.append(lose_vector)\n",
    "        one_minus_two.append(wscore-lscore)\n",
    "    \n",
    "        #Lose minus win\n",
    "        team_ones = team_ones.append(lose_vector)\n",
    "        team_twos = team_twos.append(win_vector)\n",
    "        one_minus_two.append(lscore-wscore)\n",
    "    \n",
    "    one_minus_two = pd.Series(one_minus_two)\n",
    "    return team_ones, team_twos, one_minus_two\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team_ones, new_team_twos, one_minus_two = gen_new_data(team_vector_store)\n",
    "\n",
    "# display(new_team_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we define a function to create the third model. This model has 3 hidden layers, and 15 units (1 for each feature in the feature vector) on each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_reg_model(team_feature_length):\n",
    "    \n",
    "    t1 = Input(shape = (team_feature_length, ))\n",
    "    t2 = Input(shape = (team_feature_length, ))\n",
    "    \n",
    "    team_transform = Dense(team_feature_length, \n",
    "                            activation = 'tanh', \n",
    "                            kernel_regularizer = l1_l2(0, 0.001)\n",
    "                          )\n",
    "    \n",
    "    team_1 = team_transform(t1)\n",
    "    team_2 = team_transform(t2)\n",
    "    \n",
    "    merge = Concatenate(axis=-1)([team_1, team_2])\n",
    "    \n",
    "    dropout = Dropout(0.2)(merge)\n",
    "    \n",
    "    x = Dense(2*team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(dropout)\n",
    "    \n",
    "    x = Dense(2*team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(x)\n",
    "    \n",
    "    x = Dense(2*team_feature_length,\n",
    "                activation = 'tanh',\n",
    "                kernel_regularizer = l1_l2(0, 0.001)\n",
    "             )(x)\n",
    "    \n",
    "    pred = Dense(1)(x) #linear activation for regression\n",
    "    model = Model(inputs = [t1, t2],\n",
    "                 outputs = pred)\n",
    "    model.compile(optimizer = 'Adam', loss = 'mae', metrics = [pred_percentage])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def new_train_and_evaluate(model, X_train, Y_train, X_test, Y_test, epochs):\n",
    "    model.fit(X_train, Y_train, epochs = epochs, batch_size = 1)\n",
    "    loss = model.evaluate(X_test, Y_test, batch_size = 1)\n",
    "    print(\"Loss was: {} and prediction percentage was: {}\".format(loss[0], loss[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we test this third neural network using the same process as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display(one_minus_two)\n",
    "team_feature_length = len(imp_attributes)\n",
    "\n",
    "n_folds = 10\n",
    "epochs = 5\n",
    "folds = StratifiedKFold(one_minus_two, n_folds = n_folds, shuffle = True)\n",
    "# folds = StratifiedKFold(n_folds = n_folds, shuffle=True)\n",
    "\n",
    "percentages = []\n",
    "for i, (train, test) in enumerate(folds):\n",
    "    print(\"Running fold: {}\".format(i+1))\n",
    "    model = None\n",
    "    model = make_reg_model(team_feature_length)\n",
    "    percentage = train_and_evaluate(model,\n",
    "                       [new_team_ones.iloc[train], new_team_twos.iloc[train]],\n",
    "                       one_minus_two.iloc[train], \n",
    "                       [new_team_ones.iloc[test], new_team_twos.iloc[test]],\n",
    "                       one_minus_two.iloc[test], \n",
    "                       epochs = epochs)\n",
    "    percentages.append(percentage)\n",
    "\n",
    "print(\"Average prediction accuracy: {}\".format(np.mean(percentages)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now created and tested 3 different models:\n",
    "1. Simple binary classifier. \n",
    "    - Uses our definition of matchups (team_1 - team_2), and outputs 1 if team_1 wins, 0 if team_2 wins.\n",
    "\n",
    "2. Simple Regression.\n",
    "    - Uses our definition of matchups, and tries to predict the difference between points of team_1 and team_2.\n",
    "    - We then use a scoring function (return 1 if score_diff > 0, and 0 otherwise) in order to generate predictions.\n",
    "\n",
    "3. More Complex Regression.\n",
    "    - We feed just the team vectors into the model, and let the model learn an effective definition for what a matchup is.\n",
    "    - The model then outputs a prediction of the score differential (team_1_score - team_2_score).\n",
    "    - We then use the scoring function defined above to generate predictions.\n",
    "    \n",
    "    \n",
    "\n",
    "Now we will use these models (and the training data) in order to generate predictions for the matchups between 2011-2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matchup_testing_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Function to generate the training/testing data.\n",
    "    Based on team_vector_store and the tourney detailed results.\n",
    "    If classification = True, generates for binary classification.\n",
    "    If classification = False, generates for regression.\n",
    "    \n",
    "    Returns training_data\n",
    "    \"\"\"\n",
    "    col_names = list(team_vector_store[2003])\n",
    "\n",
    "    testing_matchup_data = pd.DataFrame(columns = col_names)\n",
    "    matchups = []\n",
    "    \n",
    "    for year in [2011, 2012, 2013]:\n",
    "        season_data = team_vector_store[year].sort_index()\n",
    "        for i1, row1 in season_data.iterrows():\n",
    "            for i2, row2 in season_data.iterrows():\n",
    "#                 print(row2)\n",
    "                if i2 > i1:\n",
    "                    matchups.append([year, i1, i2])\n",
    "                    matchup = row1 - row2\n",
    "                    testing_matchup_data = testing_matchup_data.append([matchup], ignore_index = True)\n",
    "\n",
    "    return testing_matchup_data, matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup_data, matchups = generate_matchup_testing_data(team_vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_to_csv(model, X_train, Y_train, outfile, testing_data, matchups, classification = True):\n",
    "    model.fit(X_train, Y_train, epochs = 5, batch_size = 1)\n",
    "    if classification:\n",
    "        predictions = model.predict_classes(testing_data)\n",
    "    else:\n",
    "        predictions = model.predict(testing_data)\n",
    "        \n",
    "    result = []\n",
    "    for i in range(len(matchups)):\n",
    "        representation = '_'.join([str(matchups[i][0]), str(matchups[i][1]), str(matchups[i][2])])\n",
    "        if classification:\n",
    "            representation = [representation] + [str(predictions[i][0])]\n",
    "        else:\n",
    "            pred = 1 if predictions[i][0] > 0 else 0\n",
    "            representation = [representation] + [str(pred)]\n",
    "        result.append(representation)\n",
    "\n",
    "    # print(result)\n",
    "    result = pd.DataFrame(data = result, columns = ['game_ID', 'Prediction'])\n",
    "    result.to_csv(outfile, index = False, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class = train_matchup_data_class.drop(['class'], axis = 1)\n",
    "input_shape = X_train_class.shape\n",
    "Y_train_class = train_matchup_data_class['class']\n",
    "binary_class_model = build_keras_model(input_shape, \n",
    "                                       num_units = 2*len(imp_attributes), \n",
    "                                       num_layers = 3, \n",
    "                                       classification = True)\n",
    "\n",
    "# plot_model(binary_class_model, to_file = \"binary_class_model.png\")\n",
    "print(binary_class_model.summary())\n",
    "\n",
    "generate_predictions_to_csv(binary_class_model, \n",
    "                            X_train_class, \n",
    "                            Y_train_class, \n",
    "                            \"bin_predictions.csv\",\n",
    "                            matchup_data,\n",
    "                            matchups,\n",
    "                            classification = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reg = train_matchup_data_reg.drop(['class'], axis = 1)\n",
    "input_shape = X_train_reg.shape\n",
    "Y_train_reg = train_matchup_data_reg['class']\n",
    "\n",
    "simple_regression_model = build_keras_model(input_shape, \n",
    "                                            num_units = 2*len(imp_attributes), \n",
    "                                            num_layers = 3, \n",
    "                                            classification = False)\n",
    "print(simple_regression_model.summary())\n",
    "\n",
    "\n",
    "\n",
    "generate_predictions_to_csv(simple_regression_model, \n",
    "                            X_train_reg, \n",
    "                            Y_train_reg, \n",
    "                            \"simple_reg_predictions.csv\",\n",
    "                            matchup_data,\n",
    "                            matchups,\n",
    "                            classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_indiv_testing_data(team_vector_store):\n",
    "    \"\"\"\n",
    "    Function to generate the testing data.\n",
    "    \"\"\"\n",
    "    col_names = list(team_vector_store[2003])\n",
    "\n",
    "    team_ones = pd.DataFrame(columns = col_names)\n",
    "    team_twos = pd.DataFrame(columns = col_names)\n",
    "    matchups = []\n",
    "    \n",
    "    for year in [2011, 2012, 2013]:\n",
    "        season_data = team_vector_store[year].sort_index()\n",
    "        for i1, row1 in season_data.iterrows():\n",
    "            for i2, row2 in season_data.iterrows():\n",
    "#                 print(row2)\n",
    "                if i2 > i1:\n",
    "                    team_ones = team_ones.append(row1, ignore_index = True)\n",
    "                    team_twos = team_twos.append(row2, ignore_index = True)\n",
    "                    matchups.append([year, i1, i2])\n",
    "                    \n",
    "    return [team_ones, team_twos], matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [new_team_ones, new_team_twos]\n",
    "team_dim = len(imp_attributes)\n",
    "Y_train = one_minus_two\n",
    "\n",
    "complex_regression_model = make_reg_model(team_dim)\n",
    "indiv_testing_data, matchups = generate_indiv_testing_data(team_vector_store)\n",
    "\n",
    "print(complex_regression_model.summary())\n",
    "\n",
    "\n",
    "generate_predictions_to_csv(complex_regression_model,\n",
    "                           X_train,\n",
    "                           Y_train,\n",
    "                           \"complex_reg_predictions.csv\",\n",
    "                           indiv_testing_data,\n",
    "                           matchups,\n",
    "                           classification = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg_season_years)\n",
    "year = 2017\n",
    "m = team_vector_store[year]\n",
    "# display(m.loc[1274])\n",
    "# display(m.loc[1199])\n",
    "matchup_1 = (m.loc[1274] - m.loc[1199])\n",
    "matchup_1['class'] = 1\n",
    "# display(matchup_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
